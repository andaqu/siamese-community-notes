{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('notes_cleaned.csv')\n",
    "data['target'] = data['target'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forbes has a good rundown of the investigation...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they are expressing a personal opinion in a st...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teslas purchased after  are not eligible for u...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the jan th riots were encouraged by the sittin...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the committee has been found by numerous court...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62475</th>\n",
       "      <td>around  of the consultants employed by nhs eng...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62476</th>\n",
       "      <td>the poster alleges the only strategy currently...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62477</th>\n",
       "      <td>the ads elon is seeing can be stopped by eithe...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62478</th>\n",
       "      <td>jason has a personal interest in this</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62479</th>\n",
       "      <td>the corrupt legacy blue refers to people who p...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62480 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary  \\\n",
       "0      forbes has a good rundown of the investigation...   \n",
       "1      they are expressing a personal opinion in a st...   \n",
       "2      teslas purchased after  are not eligible for u...   \n",
       "3      the jan th riots were encouraged by the sittin...   \n",
       "4      the committee has been found by numerous court...   \n",
       "...                                                  ...   \n",
       "62475  around  of the consultants employed by nhs eng...   \n",
       "62476  the poster alleges the only strategy currently...   \n",
       "62477  the ads elon is seeing can be stopped by eithe...   \n",
       "62478             jason has a personal interest in this    \n",
       "62479  the corrupt legacy blue refers to people who p...   \n",
       "\n",
       "                                     target  \n",
       "0      [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]  \n",
       "2      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "4      [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "...                                     ...  \n",
       "62475  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "62476  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "62477  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "62478  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "62479  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[62480 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for _ in range(16000):\n",
    "    # Select two random indices\n",
    "    idx1, idx2 = random.sample(range(len(data)), 2)\n",
    "    \n",
    "    # Get summaries and targets for the selected indices\n",
    "    summary1, summary2 = data.loc[idx1, 'summary'], data.loc[idx2, 'summary']\n",
    "    target1, target2 = data.loc[idx1, 'target'], data.loc[idx2, 'target']\n",
    "    \n",
    "    # Determine similarity based on target\n",
    "    similar = [1 if target1[i] == 1 and target2[i] == 1 else 0 for i in range(len(target1))]\n",
    "    \n",
    "    # Add pair to the list\n",
    "    pairs.append((summary1, summary2, similar))\n",
    "\n",
    "# Convert pairs list to DataFrame\n",
    "pairs_data = pd.DataFrame(pairs, columns=['sentence1', 'sentence2', 'similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the photos clearly show that a megaphone was p...</td>\n",
       "      <td>the unsealed documents in the depp vs heard de...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>while not aligned with mainstream accepted nar...</td>\n",
       "      <td>this lacks context the town in question is not...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president magill announced an action plan to c...</td>\n",
       "      <td>post is just a question to the audience anyon...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its correct according to us government source...</td>\n",
       "      <td>these statements are false claims and are unsu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>op is expressing their personal story and out...</td>\n",
       "      <td>a common misconception is that ar is an acrony...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>bls stats states that unemployment was  in feb...</td>\n",
       "      <td>elon has a shrimp dick</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>as of the date of this  the us domestic price ...</td>\n",
       "      <td>fauci an immunologist is the presidents chief ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>bernie sanders got me arrested refers to the s...</td>\n",
       "      <td>stew peters is irresponsible and misleading it...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>ivermectin has shown no benefit for the preven...</td>\n",
       "      <td>the process is easy not convoluted the top  fr...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>the quote falsely attributed to steven crowder...</td>\n",
       "      <td>axios did not report fake news as this post cl...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence1  \\\n",
       "0      the photos clearly show that a megaphone was p...   \n",
       "1      while not aligned with mainstream accepted nar...   \n",
       "2      president magill announced an action plan to c...   \n",
       "3       its correct according to us government source...   \n",
       "4       op is expressing their personal story and out...   \n",
       "...                                                  ...   \n",
       "15995  bls stats states that unemployment was  in feb...   \n",
       "15996  as of the date of this  the us domestic price ...   \n",
       "15997  bernie sanders got me arrested refers to the s...   \n",
       "15998  ivermectin has shown no benefit for the preven...   \n",
       "15999  the quote falsely attributed to steven crowder...   \n",
       "\n",
       "                                               sentence2  \\\n",
       "0      the unsealed documents in the depp vs heard de...   \n",
       "1      this lacks context the town in question is not...   \n",
       "2       post is just a question to the audience anyon...   \n",
       "3      these statements are false claims and are unsu...   \n",
       "4      a common misconception is that ar is an acrony...   \n",
       "...                                                  ...   \n",
       "15995                             elon has a shrimp dick   \n",
       "15996  fauci an immunologist is the presidents chief ...   \n",
       "15997  stew peters is irresponsible and misleading it...   \n",
       "15998  the process is easy not convoluted the top  fr...   \n",
       "15999  axios did not report fake news as this post cl...   \n",
       "\n",
       "                                    similar  \n",
       "0      [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                     ...  \n",
       "15995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "15996  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "15997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "15998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "15999  [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "\n",
    "RATE_DROP_LSTM = 0.17\n",
    "RATE_DROP_DENSE = 0.25\n",
    "NUMBER_LSTM = 50\n",
    "NUMBER_DENSE_UNITS = 50\n",
    "ACTIVATION_FUNCTION = 'relu'\n",
    "\n",
    "\n",
    "siamese_config = {\n",
    "\t'EMBEDDING_DIM': EMBEDDING_DIM,\n",
    "\t'MAX_SEQUENCE_LENGTH' : MAX_SEQUENCE_LENGTH,\n",
    "\t'VALIDATION_SPLIT': VALIDATION_SPLIT,\n",
    "\t'RATE_DROP_LSTM': RATE_DROP_LSTM,\n",
    "\t'RATE_DROP_DENSE': RATE_DROP_DENSE,\n",
    "\t'NUMBER_LSTM': NUMBER_LSTM,\n",
    "\t'NUMBER_DENSE_UNITS': NUMBER_DENSE_UNITS,\n",
    "\t'ACTIVATION_FUNCTION': ACTIVATION_FUNCTION\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handler import word_embed_meta_data, create_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = list(pairs_data['sentence1'])\n",
    "sentences2 = list(pairs_data['sentence2'])\n",
    "similar = list(pairs_data['similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (32689, 50)\n",
      "Null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "tokenizer, embedding_matrix = word_embed_meta_data(sentences1 + sentences2,  siamese_config['EMBEDDING_DIM'])\n",
    "\n",
    "embedding_meta_data = {\n",
    "\t'tokenizer': tokenizer,\n",
    "\t'embedding_matrix': embedding_matrix\n",
    "}\n",
    "\n",
    "## creating sentence pairs\n",
    "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SiameseBiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration(object):\n",
    "    \"\"\"Dump stuff here\"\"\"\n",
    "\n",
    "CONFIG = Configuration()\n",
    "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
    "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
    "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
    "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
    "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
    "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
    "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
    "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
    "\n",
    "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, \n",
    "\t\t\t\t\t    CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
    "\n",
    "best_model_path = siamese.train_model(sentences_pair, similar, embedding_meta_data, model_save_directory='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
